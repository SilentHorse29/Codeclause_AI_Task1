{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "import webcolors\n",
    "import numpy as np  \n",
    "import numexpr as ne\n",
    "import face_recognition\n",
    "\n",
    "from imutils import paths\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "DATASET_FILE_NAME = 'model_encodings.pickle'\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_histogram(clt):\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    return hist\n",
    "\n",
    "def color(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image = image.reshape((image.shape[1] * image.shape[0], 3))\n",
    "\n",
    "    clt = KMeans(n_clusters = 8)\n",
    "    clt.fit(image)\n",
    "    hist = centroid_histogram(clt)\n",
    "    cluster_centers = list(clt.cluster_centers_)\n",
    "    labs = ['#' + ''.join([\"%0.2X\"%(j) for j in i.astype(\"uint8\").tolist()]) for i in clt.cluster_centers_]\n",
    "\n",
    "    INDEX = list(hist).index(max(hist))\n",
    "\n",
    "    return (labs[INDEX],  clt.cluster_centers_[INDEX][::-1])\n",
    "\n",
    "\n",
    "def _hex_to_name(requested_colour):\n",
    "    try:\n",
    "        closest_name = actual_name = hex_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return actual_name, closest_name\n",
    "\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    try:\n",
    "        requested_colour = hex_to_rgb(requested_colour)\n",
    "    except:\n",
    "        pass\n",
    "    for key, name in css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = ThreadPool(processes=10)\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "colors = [tuple(255 * np.random.rand(3)) for i in range(7)]\n",
    "data = pickle.loads(open(DATASET_FILE_NAME, \"rb\").read())\n",
    "\n",
    "def predict(img):\n",
    "    converted_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return tfnet.return_predict(converted_img)\n",
    "\n",
    "def say(label):\n",
    "    try:\n",
    "        engine.say(label)\n",
    "        engine.runAndWait()\n",
    "        engine.stop()\n",
    "    except: # Exception as e:\n",
    "        pass\n",
    "\n",
    "def fetchMetaInformation(result, image):\n",
    "    label = result['label']\n",
    "\n",
    "    tl = (result['topleft']['x'],result['topleft']['y'])\n",
    "    br = (result['bottomright']['x'],result['bottomright']['y'])\n",
    "\n",
    "    clipped = image[tl[1]:br[1], tl[0]:br[0]]\n",
    "\n",
    "    if label in object_with_colors:\n",
    "        try:\n",
    "            clipped = image[tl[1]:br[1], tl[0]:br[0]]\n",
    "#             color = cv2.resize(clipped, (1,1))\n",
    "#             print(color);\n",
    "#             clipped = rm_bg(clipped)\n",
    "#                 _, actual = color(clipped)\n",
    "        except:\n",
    "            actual = ''\n",
    "            pass\n",
    "\n",
    "    #  clipped = cv2.putText(clipped, actual, tl, cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    #  return \"%s %s\" % (actual, label)\n",
    "\n",
    "    #     if label == \"person\":\n",
    "    #         label = get_name(image)\n",
    "    #         print(\"person\", label)\n",
    "    return label\n",
    "\n",
    "def recz(img, prev_output):\n",
    "    label=\"\"\n",
    "    async_result = pool.apply_async(predict, (img, ))\n",
    "\n",
    "    stime = time.time()\n",
    "    results = async_result.get()\n",
    "\n",
    "    out_string = \"There is \"\n",
    "    c = 0\n",
    "\n",
    "    print(results)\n",
    "\n",
    "    for clr, result in zip(colors, results):\n",
    "        tl = (result['topleft']['x'], result['topleft']['y'])\n",
    "        br = (result['bottomright']['x'], result['bottomright']['y'])\n",
    "        label = fetchMetaInformation(result, img)\n",
    "\n",
    "        out_string += \"a %s, \" % (label)\n",
    "\n",
    "        img = cv2.rectangle(img, tl, br, clr, 7)\n",
    "        img = cv2.putText(img, label, tl, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "        c += 1\n",
    "\n",
    "    if(c > 0 and prev_output != out_string):\n",
    "        threading.Thread(target=say, args=(out_string + \".\", )).start()\n",
    "        prev_output = out_string\n",
    "\n",
    "    fps = 1 / (time.time() - stime)\n",
    "\n",
    "    img = cv2.putText(\n",
    "        img,\n",
    "        'FPS {:.1f}'.format(fps),\n",
    "        (10, 40),\n",
    "        cv2.FONT_HERSHEY_COMPLEX,\n",
    "        .8,\n",
    "        (255, 255, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    print('\\rFPS {:.1f}'.format(fps), end=\"\\r\")\n",
    "\n",
    "    return (img, prev_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BLUR = 24\n",
    "CANNY_THRESH_1 = 10\n",
    "CANNY_THRESH_2 = 200\n",
    "MASK_DILATE_ITER = 10\n",
    "MASK_ERODE_ITER = 10\n",
    "MASK_COLOR = (0.0,0.0,1.0) # In BGR format\n",
    "\n",
    "object_with_colors = [\n",
    "    'car',\n",
    "    'motorbike',\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"cow\",\n",
    "    \"umbrella\",\n",
    "    \"handbag\",\n",
    "    \"tie\",\n",
    "    \"suitcase\",\n",
    "    \"frisbee\",\n",
    "    \"kite\",\n",
    "    \"skateboard\",\n",
    "    \"bottle\",\n",
    "    \"cup\",\n",
    "    \"fork\",\n",
    "    \"knife\",\n",
    "    \"spoon\"\n",
    "    \"cell phone\",\n",
    "    \"knife\",\n",
    "    \"sofa\",\n",
    "    \"mouse\",\n",
    "    \"cake\",\n",
    "    \"clock\",\n",
    "    \"toothbrush\",\n",
    "    'mouse',\n",
    "    'bottle',\n",
    "    'laptop'\n",
    " ]\n",
    "\n",
    "def get_name(image):\n",
    "    boxes = face_recognition.face_locations(image, model='hop')\n",
    "    encodings = face_recognition.face_encodings(image, boxes)\n",
    "    # find faces\n",
    "    for encoding in encodings:\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "        num_prop = 0\n",
    "\n",
    "        if True in matches:\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "            name = max(counts, key=counts.get)\n",
    "            num_prop = counts[name] / num_names[name]\n",
    "\n",
    "            print(\"[INFO] detected %s with '%f' accuracy ...\" %\n",
    "                  (name, num_prop))\n",
    "            \n",
    "        return name if num_prop > 0.85 else \"Unknown\"\n",
    "    return None\n",
    "\n",
    "def fetchMetaInformation(result, image):\n",
    "    label = result['label']\n",
    "\n",
    "    tl = (result['topleft']['x'],result['topleft']['y'])\n",
    "    br = (result['bottomright']['x'],result['bottomright']['y'])\n",
    "\n",
    "    clipped = image[tl[1]:br[1], tl[0]:br[0]]\n",
    "\n",
    "    if label in object_with_colors:\n",
    "        try:\n",
    "            clipped = image[tl[1]:br[1], tl[0]:br[0]]\n",
    "#             color = cv2.resize(clipped, (1,1))\n",
    "#             print(color);\n",
    "#             clipped = rm_bg(clipped)\n",
    "#                 _, actual = color(clipped)\n",
    "        except:\n",
    "            actual = ''\n",
    "            pass\n",
    "\n",
    "#             clipped = cv2.putText(clipped, actual, tl, cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    #         return \"%s %s\" % (actual, label)\n",
    "\n",
    "    #     if label == \"person\":\n",
    "    #         label = get_name(image)\n",
    "    #         print(\"person\", label)\n",
    "    return label\n",
    "\n",
    "def recz(img, prev_output):\n",
    "    label=\"\"\n",
    "    async_result = pool.apply_async(predict, (img, ))\n",
    "\n",
    "    stime = time.time()\n",
    "    results = async_result.get()\n",
    "\n",
    "    out_string = \"There is \"\n",
    "    c = 0\n",
    "\n",
    "    print(results)\n",
    "\n",
    "    for clr, result in zip(colors, results):\n",
    "        tl = (result['topleft']['x'], result['topleft']['y'])\n",
    "        br = (result['bottomright']['x'], result['bottomright']['y'])\n",
    "        label = fetchMetaInformation(result, img)\n",
    "\n",
    "        out_string += \"a %s, \" % (label)\n",
    "\n",
    "        img = cv2.rectangle(img, tl, br, clr, 7)\n",
    "        img = cv2.putText(img, label, tl, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "        c += 1\n",
    "\n",
    "    if(c > 0 and prev_output != out_string):\n",
    "        threading.Thread(target=say, args=(out_string + \".\", )).start()\n",
    "        prev_output = out_string\n",
    "\n",
    "    fps = 1 / (time.time() - stime)\n",
    "\n",
    "    img = cv2.putText(\n",
    "        img,\n",
    "        'FPS {:.1f}'.format(fps),\n",
    "        (10, 40),\n",
    "        cv2.FONT_HERSHEY_COMPLEX,\n",
    "        .8,\n",
    "        (255, 255, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    print('\\rFPS {:.1f}'.format(fps), end=\"\\r\")\n",
    "\n",
    "    return (img, prev_output)\n",
    "\n",
    "def rm_bg(img):\n",
    "  hMin = 29  # Hue minimum\n",
    "  sMin = 30  # Saturation minimum\n",
    "  vMin = 0   # Value minimum (Also referred to as brightness)\n",
    "  hMax = 179 # Hue maximum\n",
    "  sMax = 255 # Saturation maximum\n",
    "  vMax = 255 # Value maximum\n",
    "  # Set the minimum and max HSV values to display in the output image using numpys' array function. We need the numpy array since OpenCVs' inRange function will use those.\n",
    "  lower = np.array([hMin, sMin, vMin])\n",
    "  upper = np.array([hMax, sMax, vMax])\n",
    "  # Create HSV Image and threshold it into the proper range.\n",
    "  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # Converting color space from BGR to HSV\n",
    "  mask = cv2.inRange(hsv, lower, upper) # Create a mask based on the lower and upper range, using the new HSV image\n",
    "  # Create the output image, using the mask created above. This will perform the removal of all unneeded colors, but will keep a black background.\n",
    "  output = cv2.bitwise_and(img, img, mask=mask)\n",
    "  # Add an alpha channel, and update the output image variable\n",
    "  *_, alpha = cv2.split(output)\n",
    "  dst = cv2.merge((output, alpha))\n",
    "  return output\n",
    "\n",
    "def color(img):\n",
    "    data = np.reshape(img, (-1,3))\n",
    "    data = np.float32(data)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 1, 1.0)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    compactness, labels, centers = cv2.kmeans(data,1,None,criteria,10,flags)\n",
    "\n",
    "    color = centers[0].astype(np.int32)\n",
    "    color = (color[0], color[1], color[2])\n",
    "    color_hex = '#%02x%02x%02x' % color\n",
    "\n",
    "    return (color_hex, get_colour_name(color)[1])\n",
    "\n",
    "def _hex_to_name(requested_colour):\n",
    "    try:\n",
    "        closest_name = actual_name = hex_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return actual_name, closest_name\n",
    "\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    try:\n",
    "        requested_colour = hex_to_rgb(requested_colour)\n",
    "    except:\n",
    "        pass\n",
    "    for key, name in css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.019945621490478516s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.67 usage\n",
      "Finished in 21.372554540634155s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = .5\n",
    "options = {\n",
    "    'model': 'cfg/yolo.cfg',\n",
    "    'load': 'bin/yolo.weights',\n",
    "    'threshold': accuracy,\n",
    "    'gpu': 0.82\n",
    "}\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "pool = ThreadPool(processes=10)\n",
    "prev_output = \"\"\n",
    "\n",
    "engine.say(\"Started\")\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img, prev_output  = recz(frame, prev_output)\n",
    "\n",
    "    cv2.imshow('ImageWindow', img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture from window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import win32gui\n",
    "from PIL import ImageGrab\n",
    "\n",
    "# hwnd = win32gui.FindWindow(None, r'192.168.43.56:4747/video')\n",
    "# hwnd = win32gui.FindWindow(None, r'DroidCam Video Feed')\n",
    "# hwnd = win32gui.FindWindow(None, r'a.mp4 - VLC Media Player')\n",
    "hwnd = win32gui.FindWindow(None, r'DroidCam Video')\n",
    "dimensions = win32gui.GetWindowRect(hwnd)\n",
    "# win32gui.SetForegroundWindow(hwnd)\n",
    "\n",
    "pool = ThreadPool(processes=3)\n",
    "prev_output = \"\"\n",
    "\n",
    "engine.say(\"Started\")\n",
    "\n",
    "while(True):\n",
    "    image = ImageGrab.grab(dimensions)\n",
    "    img = np.array(image)\n",
    "    img = img[:, :, ::-1].copy()\n",
    "\n",
    "    img, prev_output  = recz(img, prev_output)\n",
    "\n",
    "    cv2.imshow('ImageWindow', img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"./sample.jpeg\")\n",
    "prev_output = \"\"\n",
    "img, prev_output  = recz(frame, prev_output)\n",
    "\n",
    "cv2.imwrite(\"outputs/accuracy_\" + str(accuracy) +\".jpeg\", img)\n",
    "# while(True):\n",
    "#     if cv2.waitKey(1000) & 0xFF == ord('q'):\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "INPUT_FILE = \"a.mp4\" \n",
    "OUTPUT_FILE = \"out_a.avi\"\n",
    "RESZIE_WIDTH = 1920\n",
    "RESIZE_HEIGHT = int(9 / 16 * RESZIE_WIDTH)\n",
    "\n",
    "vid = cv2.VideoCapture(INPUT_FILE)\n",
    "check, org = vid.read() \n",
    "\n",
    "present_name = list()\n",
    "pool = ThreadPool(processes=10)\n",
    "\n",
    "if check:\n",
    "    rows, cols, layer = org.shape\n",
    "\n",
    "out = cv2.VideoWriter(OUTPUT_FILE, cv2.VideoWriter_fourcc(*'DIVX'), 30, (RESZIE_WIDTH, RESIZE_HEIGHT))\n",
    "prev_output = \"\"\n",
    "while True:\n",
    "    check, org = vid.read() \n",
    "\n",
    "    if org is None:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if k % 256 == 27:\n",
    "        print(\"\\nEscape hit, closing...\")\n",
    "        break\n",
    "    clear_output(wait=True)\n",
    "    image = cv2.resize(org, (RESZIE_WIDTH, RESIZE_HEIGHT))\n",
    "\n",
    "#     # rotate image\n",
    "#     M = cv2.getRotationMatrix2D((RESZIE_WIDTH / 2, RESIZE_HEIGHT / 2), -90, 1)\n",
    "#     image = cv2.warpAffine(image, M, (RESZIE_WIDTH, RESIZE_HEIGHT))\n",
    "\n",
    "    img, prev_output  = recz(image, prev_output)\n",
    "\n",
    "    out.write(img)\n",
    "    cv2.imshow(\"a\", img)\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from webcolors import rgb_percent_to_hex, hex_to_name,hex_to_rgb\n",
    "\n",
    "# read the color image and covert to RGB\n",
    "img = cv2.imread('aaaa.jpg', cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def centroid_histogram(clt):\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "\n",
    "    # return the histogram\n",
    "    return hist\n",
    "\n",
    "def plot_colors(hist, centroids):\n",
    "    # initialize the bar chart representing the relative frequency\n",
    "    # of each of the colors\n",
    "    bar = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "\n",
    "    # loop over the percentage of each cluster and the color of\n",
    "    # each cluster\n",
    "    for (percent, color) in zip(hist, centroids):\n",
    "        # plot the relative percentage of each cluster\n",
    "        endX = startX + (percent * 300)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
    "            color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "\n",
    "    # return the bar chart\n",
    "    return bar\n",
    "\n",
    "def _hex_to_name(requested_colour):\n",
    "    try:\n",
    "        closest_name = actual_name = hex_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return actual_name, closest_name\n",
    "\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    try:\n",
    "        requested_colour = hex_to_rgb(requested_colour)\n",
    "    except:\n",
    "        pass\n",
    "    for key, name in webcolors.css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "    \n",
    "def color2(image):\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    clt = KMeans(n_clusters = 3)\n",
    "    clt.fit(image)\n",
    "#     print(clt.cluster_centers_)\n",
    "#     hist = centroid_histogram(clt)\n",
    "#     bar = plot_colors(hist, clt.cluster_centers_)\n",
    "    # show our color bart\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_axes([0,0,1,1])\n",
    "    labs = [_hex_to_name('#' + ''.join([\"%0.2X\"%(j) for j in i.astype(\"uint8\").tolist()]))[1] for i in clt.cluster_centers_]\n",
    "#     print(labs)\n",
    "#     return labs[0]\n",
    "\n",
    "    ax.bar(labs, hist)\n",
    "    plt.axis(\"off\")\n",
    "    plt.hist(hist)\n",
    "    print(hist)\n",
    "    plt.show()\n",
    "    plt.imshow(bar)\n",
    "    print([(i,j) for i,j in zip(hist, clt.cluster_centers_)])\n",
    "\n",
    "results = tfnet.return_predict(img)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for clr, result in zip(colors, results):\n",
    "    tl = (result['topleft']['x'], result['topleft']['y'])\n",
    "    br = (result['bottomright']['x'], result['bottomright']['y'])\n",
    "    label = result['label']\n",
    "    clipped = img[tl[1]:br[1], tl[0]:br[0]]\n",
    "\n",
    "    # try:\n",
    "    #     clipped = rm_bg(clipped)\n",
    "    # except:\n",
    "# \n",
    "#     clipped = rm_bg(clipped)\n",
    "    clipped = cv2.cvtColor(clipped, cv2.COLOR_RGB2BGR)\n",
    "    print(color(clipped))\n",
    "    \n",
    "    img = cv2.rectangle(img, tl, br, clr, 7)\n",
    "    img = cv2.putText(img, label, tl, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2)\n",
    "#     cv2.imshow(label, clipped)\n",
    "\n",
    "# add the box and label and display itq\n",
    "clipped = cv2.cvtColor(clipped, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.imshow(\"f\", img)\n",
    "cv2.waitKey(100000)\n",
    "cv2.destroyAllWindows()\n",
    "# cv2.imshow(\"pre\", img)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(DATASET_FILE_NAME, \"rb\").read())\n",
    "\n",
    "print(\"[INFO] recognizing faces...\")\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 480)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)\n",
    "\n",
    "cv2.namedWindow(\"recognize faces\")\n",
    "\n",
    "num_names = Counter(data['names'])\n",
    "present_name = list()\n",
    "\n",
    "while True:\n",
    "    ret, image = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if k % 256 == 27:\n",
    "        print(\"\\nEscape hit, closing...\")\n",
    "        break\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    boxes = face_recognition.face_locations(image, model='hop')\n",
    "    encodings = face_recognition.face_encodings(image, boxes)\n",
    "    names, present_name = [], []\n",
    "\n",
    "    # find faces    \n",
    "    for encoding in encodings:\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "        num_prop = 0\n",
    "\n",
    "        if True in matches:\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "            name = max(counts, key=counts.get)\n",
    "            num_prop = counts[name] / num_names[name]\n",
    "\n",
    "            print(\"[INFO] detected %s with '%f' accuracy ...\" %\n",
    "                  (name, num_prop))\n",
    "\n",
    "        if(num_prop > 0.85):\n",
    "            t = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            print(\"[INFO] Found %s (%f).\" % (name, num_prop))\n",
    "\n",
    "            present_name.append(name)\n",
    "\n",
    "        names.append(name if num_prop > 0.85 else \"Unknown\")\n",
    "\n",
    "    # draw rectangle over found faces\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "      \n",
    "        left, top, right, bottom = left - 40, top - 80, right + 40, bottom + 20\n",
    "        \n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (255, 0, 0), 2)\n",
    "        \n",
    "        s = cv2.getTextSize(name, FONT, 0.75, 1)\n",
    "\n",
    "        cv2.rectangle(image, (left, top), (left + s[0][0] + 40,  top + s[0][1] + 20), (255, 0, 0), -1)\n",
    "        name = name.replace(\"_\", \" \")\n",
    "        name = name.title()\n",
    "\n",
    "        cv2.putText(image, name, (left + 20, top + 10 + s[0][1]), FONT, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"recognize faces\", image)\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def bincount_numexpr_app(a):\n",
    "    a2D = a.reshape(-1,a.shape[-1])\n",
    "    col_range = (256, 256, 256) # generically : a2D.max(0)+1\n",
    "    eval_params = {'a0':a2D[:,0],'a1':a2D[:,1],'a2':a2D[:,2],\n",
    "                   's0':col_range[0],'s1':col_range[1]}\n",
    "    a1D = ne.evaluate('a0*s0*s1+a1*s0+a2',eval_params)\n",
    "    return np.unravel_index(np.bincount(a1D).argmax(), col_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Facial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from imutils import paths\n",
    "\n",
    "TRAINING_DATASET = 'dataset_training'\n",
    "TESTING_DATASET = 'dataset_testing'\n",
    "\n",
    "print(\"[INFO] fetching images...\")\n",
    "image_paths = list(paths.list_images(TRAINING_DATASET))\n",
    "\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "num_images = len(image_paths)\n",
    "\n",
    "for (i, image_path) in enumerate(image_paths):\n",
    "    name = image_path.split(os.path.sep)[-2]\n",
    "    print(\"[INFO] processing image (%s) %d/%d...\" % (name, i + 1, num_images), end=\"\\r\")\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    boxes = face_recognition.face_locations(image, model='cnn')\n",
    "\n",
    "    encodings = face_recognition.face_encodings(image, boxes)\n",
    "\n",
    "    for encoding in encodings:\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    " \n",
    "print(\"\\n[INFO] serializing encodings...\")\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "\n",
    "f = open(DATASET_FILE_NAME, \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()\n",
    "\n",
    "print(\"[INFO] DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit16b3547e794943fdaee56569cafc8197"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
