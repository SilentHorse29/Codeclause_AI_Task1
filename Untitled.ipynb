{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  \n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "from darkflow.net.build import TFNet\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from webcolors import rgb_percent_to_hex, hex_to_name, hex_to_rgb, css3_hex_to_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_histogram(clt):\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    return hist\n",
    "\n",
    "def get_color(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image = image.reshape((image.shape[1] * image.shape[0], 3))\n",
    "\n",
    "    clt = KMeans(n_clusters = 2)\n",
    "    clt.fit(image)\n",
    "    hist = centroid_histogram(clt)\n",
    "    cluster_centers = list(clt.cluster_centers_)\n",
    "    labs = ['#' + ''.join([\"%0.2X\"%(j) for j in i.astype(\"uint8\").tolist()]) for i in clt.cluster_centers_]\n",
    "    \n",
    "#     plt_graph(hist, cluster_centers)\n",
    "    \n",
    "    INDEX = list(hist).index(max(hist))\n",
    "    \n",
    "    return (labs[INDEX],  clt.cluster_centers_[INDEX][::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex to name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hex_to_name(requested_colour):\n",
    "    try:\n",
    "        closest_name = actual_name = hex_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return actual_name, closest_name\n",
    "\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    try:\n",
    "        requested_colour = hex_to_rgb(requested_colour)\n",
    "    except:\n",
    "        pass\n",
    "    for key, name in css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconize Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_with_colors = [\n",
    "    'car',\n",
    "    'motorbike',\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"cow\",\n",
    "    \"umbrella\",\n",
    "    \"handbag\",\n",
    "    \"tie\",\n",
    "    \"suitcase\",\n",
    "    \"frisbee\",\n",
    "    \"kite\",\n",
    "    \"skateboard\",\n",
    "    \"bottle\",\n",
    "    \"cup\",\n",
    "    \"fork\",\n",
    "    \"knife\",\n",
    "    \"spoon\"\n",
    "    \"cell phone\",\n",
    "    \"knife\",\n",
    "    \"sofa\",\n",
    "    \"mouse\",\n",
    "    \"cake\",\n",
    "    \"clock\",\n",
    "    \"toothbrush\",\n",
    "    'mouse',\n",
    "    'bottle',\n",
    "    'laptop'\n",
    "    'teady bear'\n",
    "]\n",
    "font = cv2.FONT_HERSHEY_COMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def say(label):\n",
    "    try:\n",
    "        pass\n",
    "#         engine.say(label)\n",
    "#         engine.runAndWait()\n",
    "#         engine.stop()\n",
    "    except: # Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillInfo(image, result):\n",
    "    label = result['label']\n",
    "    image_label = label + \" \" + (\"{:.2f}\".format(result['confidence'])) + '%'\n",
    "\n",
    "    tl = (result['topleft']['x'],result['topleft']['y'])\n",
    "    br = (result['bottomright']['x'],result['bottomright']['y'])\n",
    "\n",
    "    clipped = image[tl[1]:br[1], tl[0]:br[0]]\n",
    "\n",
    "    hex_color, colr_set = get_color(clipped)\n",
    "    if label in object_with_colors:    \n",
    "        color = _hex_to_name(hex_color)[1]\n",
    "        image_label = color + \" \" + image_label\n",
    "        label = color + \" \" + label\n",
    "\n",
    "#     colr_set = tuple(255 * np.random.rand(3))\n",
    "    (text_width, text_height) = cv2.getTextSize(image_label, font, fontScale=1, thickness=1)[0]\n",
    "    text_offset_x = 10\n",
    "    text_offset_y = image.shape[0] - 25\n",
    "    box_coords = ((tl[0], tl[1]), (tl[0] + text_width + 2, tl[1]-10 - text_height - 2))\n",
    "    cv2.rectangle(image, box_coords[0], box_coords[1], colr_set, cv2.FILLED)\n",
    "    cv2.putText(image, image_label, (tl[0], tl[1]-10), font, fontScale=1, color=(255,255,255), thickness=1)\n",
    "\n",
    "    image = cv2.rectangle(image, tl, br, colr_set, 2)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def predict(image):\n",
    "    return tfnet.return_predict(image)\n",
    "\n",
    "def recz(image, prev_output):\n",
    "    label = \"\"\n",
    "    async_result = pool.apply_async(predict, (image, ))\n",
    "\n",
    "#     stime = time()\n",
    "    results = async_result.get()\n",
    "\n",
    "    out_string = \"There is \"\n",
    "    c = 0\n",
    "\n",
    "    for result in results:\n",
    "        image, label = fillInfo(image, result)\n",
    "\n",
    "        out_string += \"%s, \" % (label)\n",
    "        c += 1\n",
    "   \n",
    "    if(c > 0 and prev_output != out_string):\n",
    "        out_string = out_string[:-2]\n",
    "        out_string += \".\";   \n",
    "        threading.Thread(target=say, args=(out_string, )).start()\n",
    "\n",
    "#     fps = 1 / (time() - stime)\n",
    "\n",
    "#     fps = 'FPS {:.1f}'.format(fps)\n",
    "#     (text_width, text_height) = cv2.getTextSize(fps, font, fontScale=1, thickness=1)[0]\n",
    "#     box_coords = ((0, 0), (text_width + 4, text_height + 4))\n",
    "#     cv2.rectangle(image, box_coords[0], box_coords[1], (255,255,255), cv2.FILLED)\n",
    "#     cv2.putText(image, fps, (2, text_height + 2), font, fontScale=1, color=(0, 0, 255), thickness=1)\n",
    "\n",
    "    (text_width, text_height) = cv2.getTextSize(out_string, font, fontScale=1, thickness=1)[0]\n",
    "    box_coords = ((0, image.shape[0] - text_height - 4), (text_width + 2, image.shape[0]))\n",
    "    cv2.rectangle(image, box_coords[0], box_coords[1], (255,255,255), cv2.FILLED)\n",
    "    cv2.putText(image, out_string, (1, image.shape[0] - 2 ), font, 1, (0, 0, 0), 1)\n",
    "\n",
    "    return image, out_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.07779097557067871s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.85 usage\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7a445f67be17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtfnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\darkflow\\net\\build.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, FLAGS, darknet)\u001b[0m\n\u001b[0;32m     74\u001b[0m                         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_meta_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \t\tself.say('Finished in {}s\\n'.format(\n\u001b[0;32m     78\u001b[0m \t\t\ttime.time() - start))\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\darkflow\\net\\build.py\u001b[0m in \u001b[0;36msetup_meta_ops\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, target, graph, config)\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1493\u001b[0m     \"\"\"\n\u001b[1;32m-> 1494\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1495\u001b[0m     \u001b[1;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, target, graph, config)\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold = 0.45\n",
    "options = {\n",
    "    'model': 'cfg/yolo.cfg',\n",
    "    'load': 'bin/yolo.weights',\n",
    "    'threshold': threshold,\n",
    "    'gpu': 0.85\n",
    "}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "pool = ThreadPool(processes=10)\n",
    "prev_output = \"\"\n",
    "engine = pyttsx3.init()\n",
    "engine.say(\"Started\")\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image, prev_output  = recz(frame, prev_output)\n",
    "\n",
    "    print(prev_output)\n",
    "\n",
    "    cv2.imshow('ImageWindow', image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32gui\n",
    "from PIL import ImageGrab\n",
    "\n",
    "# hwnd = win32gui.FindWindow(None, r'192.168.43.56:4747/video')\n",
    "hwnd = win32gui.FindWindow(None, r'DroidCam Video Feed')\n",
    "# hwnd = win32gui.FindWindow(None, r'a.mp4 - VLC Media Player')\n",
    "# hwnd = win32gui.FindWindow(None, r'DroidCam Video')\n",
    "dimensions = win32gui.GetWindowRect(hwnd)\n",
    "# win32gui.SetForegroundWindow(hwnd)\n",
    "\n",
    "pool = ThreadPool(processes=3)\n",
    "prev_output = \"\"\n",
    "\n",
    "engine.say(\"Started\")\n",
    "\n",
    "while(True):\n",
    "    image = ImageGrab.grab(dimensions)\n",
    "    img = np.array(image)\n",
    "    img = img[:, :, ::-1].copy()\n",
    "\n",
    "    img, prev_output  = recz(img, prev_output)\n",
    "\n",
    "    cv2.imshow('ImageWindow', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 9.57ss\r"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "NPUT_FILE = \"./VID_20200501_102816.mp4\"\n",
    "OUTPUT_FILE = \"./outputs/vid_\" + str(output_count) + \".avi\"\n",
    "\n",
    "pool = ThreadPool(processes=3)\n",
    "prev_output = \"\"\n",
    "\n",
    "ORGINAL_WIDTH = 3840\n",
    "ORGINAL_HEIGHT = 2160\n",
    "\n",
    "RESZIE_WIDTH = int(ORGINAL_WIDTH * 0.5)\n",
    "RESIZE_HEIGHT = int(ORGINAL_HEIGHT * 0.5) #int(9 / 16 * RESZIE_WIDTH)\n",
    "\n",
    "vid = cv2.VideoCapture(INPUT_FILE)\n",
    "out = cv2.VideoWriter(OUTPUT_FILE, cv2.VideoWriter_fourcc(*'DIVX'), 25, ( RESIZE_HEIGHT, RESZIE_WIDTH))\n",
    "# total = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "total = 280\n",
    "for i in range(0, total + 1):\n",
    "    s = time()\n",
    "    sys.stdout.flush()\n",
    "    check, frame = vid.read()\n",
    "    frame = cv2.resize(frame, (RESZIE_WIDTH, RESIZE_HEIGHT))\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    image, prev_output  = recz(frame, prev_output)\n",
    "    out.write(image)\n",
    "#     cv2.imshow('ImageWindow', frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         cv2.destroyAllWindows()\n",
    "#         cap.release()\n",
    "#         break\n",
    "    e = time()\n",
    "    print(\"\\r{:d}/{:d} {:.2f}s\".format(i, total, e-s), end=\"\\r\")\n",
    "\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "output_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit16b3547e794943fdaee56569cafc8197"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
